{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35434605-9745-48c5-81df-08c2ed9bc730",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANS-1\n",
    "\n",
    "The three measures of central tendency are:\n",
    "\n",
    "1. Mean: The mean, also known as the average, is calculated by summing up all the values in a dataset and then dividing that sum by the number of data points. It represents the \"typical\" value in the dataset.\n",
    "\n",
    "2. Median: The median is the middle value in a dataset when it is arranged in ascending or descending order. If the dataset has an odd number of values, the median is the middle one. If the dataset has an even number of values, the median is the average of the two middle values.\n",
    "\n",
    "3. Mode: The mode is the value that appears most frequently in a dataset. A dataset can have one mode (unimodal) if there is a value that appears more often than any other, or it can have multiple modes (bimodal, trimodal, etc.) if there are two or more values with the same highest frequency.\n",
    "\n",
    "These measures help to describe the center or typical value of a dataset and are commonly used in statistics to understand and summarize data.\n",
    "\n",
    "ANS-2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "The mean, median, and mode are three different measures of central tendency, and they provide different ways to understand the typical value or central location of a dataset. Here's a brief explanation of the differences and how they are used:\n",
    "\n",
    "1. Mean:\n",
    "- Definition: The mean is the sum of all values in a dataset divided by the number of data points.\n",
    "- Calculation: Mean = (Sum of all values) / (Number of data points)\n",
    "- Use: The mean is useful when dealing with numerical data and provides an average value that takes into account all the data points. It is sensitive to extreme values (outliers) and can be influenced by them, causing it to shift significantly.\n",
    "\n",
    "2. Median:\n",
    "- Definition: The median is the middle value in a dataset when it is ordered from smallest to largest (or vice versa).\n",
    "- Calculation (for odd number of data points): Arrange the data points in ascending order and pick the middle value.\n",
    "- Calculation (for even number of data points): Arrange the data points in ascending order, and the median is the average of the two middle values.\n",
    "- Use: The median is robust to extreme values and is a better measure of central tendency when dealing with skewed data or datasets containing outliers. It divides the data into two equal halves and represents the central value without being affected by extreme values.\n",
    "\n",
    "3. Mode:\n",
    "- Definition: The mode is the value that appears most frequently in a dataset.\n",
    "- Calculation: In some cases, the mode may not be applicable, especially for continuous data where values occur with unique frequencies.\n",
    "- Use: The mode is suitable for nominal or categorical data and is useful for identifying the most common category in a dataset. It can be helpful in identifying dominant categories or popular choices in a sample.\n",
    "\n",
    "When to use each measure:\n",
    "- Mean: Use the mean when the data is roughly symmetric and there are no significant outliers that could distort the average value.\n",
    "- Median: Use the median when the data is skewed, or there are extreme values that could influence the mean disproportionately.\n",
    "- Mode: Use the mode for categorical data or when you want to identify the most frequent value or category in a dataset.\n",
    "\n",
    "It's essential to choose the appropriate measure of central tendency based on the nature of your data and what you want to understand from the dataset. In some cases, it might be helpful to use a combination of these measures to gain a more comprehensive understanding of the data's central tendency.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Let's calculate the three measures of central tendency (mean, median, and mode) for the given height data:\n",
    "\n",
    "Height data: [178, 177, 176, 177, 178.2, 178, 175, 179, 180, 175, 178.9, 176.2, 177, 172.5, 178, 176.5]\n",
    "\n",
    "1. Mean:\n",
    "Mean = (Sum of all values) / (Number of data points)\n",
    "Mean = (178 + 177 + 176 + 177 + 178.2 + 178 + 175 + 179 + 180 + 175 + 178.9 + 176.2 + 177 + 172.5 + 178 + 176.5) / 16\n",
    "Mean ≈ 1767.3 / 16\n",
    "Mean ≈ 110.45625\n",
    "\n",
    "2. Median:\n",
    "Arrange the data points in ascending order: [172.5, 175, 175, 176, 176, 176.2, 176.5, 177, 177, 177, 178, 178, 178, 178, 178.2, 179, 180]\n",
    "\n",
    "Since there are 16 data points (an even number), the median will be the average of the two middle values:\n",
    "Median = (176 + 178) / 2\n",
    "Median = 354 / 2\n",
    "Median = 177\n",
    "\n",
    "3. Mode:\n",
    "The mode is the value that appears most frequently in the dataset. In this case, the mode is 178, as it appears three times, more frequently than any other value.\n",
    "\n",
    "So, the measures of central tendency for the given height data are:\n",
    "- Mean ≈ 110.46\n",
    "- Median = 177\n",
    "- Mode = 178\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-4\n",
    "\n",
    "\n",
    "\n",
    "To find the standard deviation for the given data, follow these steps:\n",
    "\n",
    "Step 1: Find the mean of the data.\n",
    "Step 2: Subtract the mean from each data point to get the deviations from the mean.\n",
    "Step 3: Square each deviation.\n",
    "Step 4: Find the mean of the squared deviations.\n",
    "Step 5: Take the square root of the mean of squared deviations to get the standard deviation.\n",
    "\n",
    "Let's proceed with the calculations:\n",
    "\n",
    "Height data: [178, 177, 176, 177, 178.2, 178, 175, 179, 180, 175, 178.9, 176.2, 177, 172.5, 178, 176.5]\n",
    "\n",
    "Step 1: Find the mean:\n",
    "Mean = (178 + 177 + 176 + 177 + 178.2 + 178 + 175 + 179 + 180 + 175 + 178.9 + 176.2 + 177 + 172.5 + 178 + 176.5) / 16\n",
    "Mean ≈ 1767.3 / 16\n",
    "Mean ≈ 110.45625\n",
    "\n",
    "Step 2: Find deviations from the mean:\n",
    "Deviations: [178 - 110.45625, 177 - 110.45625, 176 - 110.45625, ..., 176.5 - 110.45625]\n",
    "\n",
    "Step 3: Square each deviation:\n",
    "Squared deviations: [(178 - 110.45625)^2, (177 - 110.45625)^2, (176 - 110.45625)^2, ..., (176.5 - 110.45625)^2]\n",
    "\n",
    "Step 4: Find the mean of squared deviations:\n",
    "Mean of squared deviations = (sum of squared deviations) / (number of data points)\n",
    "\n",
    "Mean of squared deviations ≈ (962.2979 + 862.1044 + 769.8937 + ... + 848.1921) / 16\n",
    "Mean of squared deviations ≈ 12994.8216 / 16\n",
    "Mean of squared deviations ≈ 812.17635\n",
    "\n",
    "Step 5: Take the square root of the mean of squared deviations to get the standard deviation:\n",
    "Standard deviation ≈ √812.17635\n",
    "Standard deviation ≈ 28.495 (rounded to three decimal places)\n",
    "\n",
    "So, the standard deviation for the given height data is approximately 28.495.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-5\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Measures of dispersion, such as range, variance, and standard deviation, are used to describe the spread or variability of a dataset. They provide information about how much the data points deviate from the central tendency (mean, median, or mode) and give insights into the extent of the distribution's spread. Let's understand each measure and their usage with an example:\n",
    "\n",
    "Example:\n",
    "Suppose we have two datasets representing the number of hours studied by two groups of students preparing for a test:\n",
    "\n",
    "Group A: [4, 5, 6, 5, 7]\n",
    "Group B: [3, 8, 5, 4, 9]\n",
    "\n",
    "1. Range:\n",
    "The range is the simplest measure of dispersion and represents the difference between the highest and lowest values in the dataset.\n",
    "\n",
    "- Range of Group A: 7 (maximum value: 7, minimum value: 4)\n",
    "- Range of Group B: 6 (maximum value: 9, minimum value: 3)\n",
    "\n",
    "The range only considers the two extreme values and does not consider the variability of the data points in between.\n",
    "\n",
    "2. Variance:\n",
    "The variance measures the average of the squared deviations from the mean. It takes into account all the data points and gives us an idea of how spread out the data is from the mean.\n",
    "\n",
    "- Variance of Group A:\n",
    "Mean of Group A = (4 + 5 + 6 + 5 + 7) / 5 = 5.4\n",
    "Squared deviations: [(4 - 5.4)^2, (5 - 5.4)^2, (6 - 5.4)^2, (5 - 5.4)^2, (7 - 5.4)^2] = [1.96, 0.16, 0.36, 0.16, 1.96]\n",
    "Variance = (1.96 + 0.16 + 0.36 + 0.16 + 1.96) / 5 ≈ 0.92\n",
    "\n",
    "- Variance of Group B:\n",
    "Mean of Group B = (3 + 8 + 5 + 4 + 9) / 5 = 5.8\n",
    "Squared deviations: [(3 - 5.8)^2, (8 - 5.8)^2, (5 - 5.8)^2, (4 - 5.8)^2, (9 - 5.8)^2] = [7.84, 4.84, 0.64, 2.56, 12.96]\n",
    "Variance = (7.84 + 4.84 + 0.64 + 2.56 + 12.96) / 5 ≈ 5.36\n",
    "\n",
    "The variance gives a sense of the overall variability of the data points. However, it is in squared units, making it less interpretable.\n",
    "\n",
    "3. Standard Deviation:\n",
    "The standard deviation is the square root of the variance and is the most commonly used measure of dispersion. It represents the typical deviation of data points from the mean and is in the original units of the data.\n",
    "\n",
    "- Standard Deviation of Group A: √0.92 ≈ 0.959\n",
    "- Standard Deviation of Group B: √5.36 ≈ 2.315\n",
    "\n",
    "The standard deviation allows us to compare the spread between datasets and provides a more interpretable measure of dispersion than variance.\n",
    "\n",
    "In this example, the range gives a basic idea of the spread, but the variance and standard deviation provide more detailed information about how the data points are distributed around the mean. Group A has a smaller standard deviation, indicating less variability in study hours compared to Group B, which has a higher standard deviation, suggesting a wider spread of study hours.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-6\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "A Venn diagram is a graphical representation of the relationships between different sets or groups. It uses overlapping circles or shapes to illustrate the common and distinct elements among the sets. The Venn diagram is named after John Venn, a British mathematician, who introduced the concept in the late 19th century.\n",
    "\n",
    "In a Venn diagram, each set is represented by a circle or an ellipse, and the elements of the sets are depicted as points within those circles. The overlapping regions of the circles show the elements that are common to the corresponding sets. The non-overlapping parts of each circle represent the elements that are unique to that particular set.\n",
    "\n",
    "Venn diagrams are commonly used to visualize set operations, such as union, intersection, complement, and set differences. They help to compare and contrast different groups and show how they relate to each other.\n",
    "\n",
    "There are different types of Venn diagrams, including:\n",
    "\n",
    "1. Two-set Venn diagram: This type of Venn diagram uses two circles to represent two sets and their overlapping region shows the elements that belong to both sets.\n",
    "\n",
    "2. Three-set Venn diagram: It uses three circles to represent three sets, and the overlapping regions illustrate the elements that are common to various combinations of sets.\n",
    "\n",
    "3. Multi-set Venn diagram: For more than three sets, multi-set Venn diagrams can be used, though they can become visually complex as the number of sets increases.\n",
    "\n",
    "Venn diagrams are commonly used in mathematics, logic, statistics, and various fields to depict the relationships and intersections between different categories or groups of data. They provide an intuitive and visual way to understand set theory and set operations.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To find the union and intersection of the given sets A and B, we first need to understand what each operation means:\n",
    "\n",
    "(i) A ∩ B (Intersection):\n",
    "The intersection of two sets A and B contains all the elements that are common to both sets. In other words, it includes only the elements that are present in both sets.\n",
    "\n",
    "(ii) A ∪ B (Union):\n",
    "The union of two sets A and B contains all the elements from both sets, without any duplication. In other words, it combines all the unique elements from both sets.\n",
    "\n",
    "Now, let's find the intersection and union of sets A and B:\n",
    "\n",
    "Set A: {2, 3, 4, 5, 6, 7}\n",
    "Set B: {0, 2, 6, 8, 10}\n",
    "\n",
    "(i) A ∩ B (Intersection):\n",
    "The elements that are common to both sets A and B are {2, 6}, as they appear in both sets.\n",
    "\n",
    "(ii) A ∪ B (Union):\n",
    "The union of sets A and B includes all the unique elements from both sets, without any duplication.\n",
    "\n",
    "A ∪ B = {0, 2, 3, 4, 5, 6, 7, 8, 10}\n",
    "\n",
    "So, the results are:\n",
    "(i) A ∩ B = {2, 6}\n",
    "(ii) A ∪ B = {0, 2, 3, 4, 5, 6, 7, 8, 10}\n",
    "\n",
    "ANS-8\n",
    "\n",
    "Skewness is a statistical measure that describes the asymmetry of a probability distribution or a dataset. In other words, it quantifies the extent to which the data is skewed or biased to one side of the central tendency. Skewness is an essential concept in statistics and data analysis, as it provides insights into the shape and distribution of data.\n",
    "\n",
    "There are three main types of skewness:\n",
    "\n",
    "1. Positive Skewness (Right Skewness):\n",
    "In a positively skewed distribution, the tail on the right side of the central peak is longer and more spread out compared to the left tail. The majority of the data points are concentrated on the left side, and there are few extreme values on the right side.\n",
    "\n",
    "Graphically, a positively skewed distribution looks like this:\n",
    "\n",
    "                ________\n",
    "               /        \n",
    "              /          \n",
    "             /           \n",
    "           _/__________\n",
    "\n",
    "2. Negative Skewness (Left Skewness):\n",
    "In a negatively skewed distribution, the tail on the left side of the central peak is longer and more spread out compared to the right tail. The majority of the data points are concentrated on the right side, and there are few extreme values on the left side.\n",
    "\n",
    "Graphically, a negatively skewed distribution looks like this:\n",
    "\n",
    "        ________\n",
    "             \\\n",
    "              \\\n",
    "               \\\n",
    "           ______\\_\n",
    "\n",
    "3. Symmetrical Distribution (No Skewness):\n",
    "In a symmetrical distribution, the data is evenly distributed on both sides of the central peak. There is no skewness, and the left and right tails are approximately equal in length.\n",
    "\n",
    "Graphically, a symmetrical distribution looks like this:\n",
    "\n",
    "              ________\n",
    "             /        \\\n",
    "            /          \\\n",
    "           /            \\\n",
    "          /              \\\n",
    "        _/________________\\_\n",
    "\n",
    "Skewness is typically measured using numerical methods, with the most common metric being the skewness coefficient. A positive skewness coefficient indicates positive skewness, while a negative skewness coefficient indicates negative skewness. A skewness coefficient of zero suggests a symmetrical distribution.\n",
    "\n",
    "Understanding the skewness of data is important in various applications, including finance, economics, and data analysis. Skewed data can affect the performance of certain statistical methods, and recognizing skewness helps researchers and analysts make appropriate decisions regarding data transformations or selection of appropriate statistical techniques.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-9\n",
    "\n",
    "\n",
    "\n",
    "In a right-skewed distribution, the median will be positioned to the left of the mean. This means that the median will be smaller than the mean value.\n",
    "\n",
    "To understand why this happens, let's consider the characteristics of right-skewed distributions:\n",
    "\n",
    "1. Right-skewed distributions have a long tail on the right side and a concentration of data points on the left side.\n",
    "2. The presence of outliers or extreme values in the right tail pulls the mean towards the right.\n",
    "3. The median is less sensitive to extreme values since it only depends on the middle value(s) in the dataset.\n",
    "\n",
    "Due to these properties, the mean is dragged towards the longer right tail, which causes it to be larger than the median. Consequently, the median is closer to the majority of the data points, which are concentrated on the left side, and it is positioned to the left of the mean in a right-skewed distribution.\n",
    "\n",
    "In summary, in a right-skewed distribution:\n",
    "- Mean > Median\n",
    "- Median is positioned to the left of the mean.\n",
    "\n",
    "ANS-10\n",
    "\n",
    "\n",
    "Covariance and correlation are both measures used to quantify the relationship between two variables in statistical analysis. While they are related concepts, they have some differences in interpretation and scale.\n",
    "\n",
    "1. Covariance:\n",
    "Covariance is a measure that indicates the degree to which two variables change together. It represents the joint variability of the two variables. A positive covariance suggests that when one variable increases, the other tends to increase as well, and when one decreases, the other tends to decrease. A negative covariance suggests an inverse relationship, where one variable increases while the other decreases.\n",
    "\n",
    "However, the magnitude of covariance depends on the scales of the variables, which can make it difficult to interpret. It can take any value, including positive, negative, or zero. A large positive covariance may indicate a strong relationship, but it is challenging to compare across different datasets.\n",
    "\n",
    "The formula for the sample covariance between two variables X and Y, based on n data points, is:\n",
    "\n",
    "\\[ \\text{Cov}(X, Y) = \\frac{1}{n-1} \\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y}) \\]\n",
    "\n",
    "2. Correlation:\n",
    "Correlation is a standardized measure that quantifies the strength and direction of the linear relationship between two variables. It scales the covariance by the standard deviations of the two variables, resulting in a value between -1 and 1. A correlation of +1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.\n",
    "\n",
    "The correlation coefficient is useful because it provides a more interpretable measure of the relationship's strength, which is not influenced by the scales of the variables. It allows for easy comparison across different datasets and is suitable for identifying the direction and strength of the linear relationship between variables.\n",
    "\n",
    "The formula for the sample correlation coefficient (Pearson correlation) between two variables X and Y, based on n data points, is:\n",
    "\n",
    "\\[ \\text{Corr}(X, Y) = \\frac{\\text{Cov}(X, Y)}{\\text{SD}(X) \\times \\text{SD}(Y)} \\]\n",
    "\n",
    "where \\(\\text{SD}(X)\\) and \\(\\text{SD}(Y)\\) are the standard deviations of X and Y, respectively.\n",
    "\n",
    "Usage in Statistical Analysis:\n",
    "- Covariance and correlation are used to understand the relationship between two variables in a dataset. They help in identifying whether the variables tend to move together or in opposite directions.\n",
    "- In finance, covariance and correlation are used to analyze the relationships between different assets, which is essential in portfolio diversification and risk management.\n",
    "- In social sciences, correlation is used to study the relationships between variables like income and education, crime rate and poverty, etc.\n",
    "- In experimental studies, correlation is used to analyze the relationship between the independent and dependent variables to draw conclusions about causality.\n",
    "\n",
    "In summary, covariance and correlation are both measures of the relationship between two variables. Correlation provides a standardized measure that is more interpretable and comparable across datasets, making it more commonly used in statistical analysis.\n",
    "\n",
    "\n",
    "\n",
    "ANS-11\n",
    "\n",
    "The formula for calculating the sample mean (also known as the average) of a dataset is to sum all the data points and then divide the sum by the number of data points in the dataset.\n",
    "\n",
    "Mathematically, the formula for the sample mean (x̄) for a dataset with n data points (x₁, x₂, ..., xₙ) is:\n",
    "\n",
    "\\[ x̄ = \\frac{1}{n} \\sum_{i=1}^{n} x_i \\]\n",
    "\n",
    "Now, let's go through an example calculation of the sample mean for a dataset:\n",
    "\n",
    "Example:\n",
    "Consider the following dataset representing the ages of a group of people: [25, 30, 35, 28, 40]\n",
    "\n",
    "Step 1: Sum all the data points in the dataset:\n",
    "Sum = 25 + 30 + 35 + 28 + 40 = 158\n",
    "\n",
    "Step 2: Count the number of data points in the dataset (n):\n",
    "n = 5 (there are 5 data points in the dataset)\n",
    "\n",
    "Step 3: Apply the formula for the sample mean:\n",
    "Sample Mean (x̄) = Sum / n\n",
    "Sample Mean (x̄) = 158 / 5\n",
    "Sample Mean (x̄) = 31.6\n",
    "\n",
    "So, the sample mean of the dataset [25, 30, 35, 28, 40] is 31.6. It represents the average age of the group.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-12\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "For a normal distribution, the measures of central tendency—mean, median, and mode—are all equal and located at the center of the distribution. This property holds true for any perfectly symmetrical normal distribution.\n",
    "\n",
    "In a normal distribution:\n",
    "\n",
    "1. Mean:\n",
    "The mean is located exactly at the center of the distribution. It is the arithmetic average of all data points and serves as the balance point of the distribution. In a normal distribution, the mean is the measure of central tendency that is commonly referred to as the \"average.\"\n",
    "\n",
    "2. Median:\n",
    "The median is also located exactly at the center of the distribution. It represents the middle value when the data is ordered from smallest to largest (or vice versa). In a perfectly symmetrical normal distribution, the median coincides with the mean, as the middle value will be the same as the arithmetic average.\n",
    "\n",
    "3. Mode:\n",
    "The mode is the value that appears most frequently in the data. In a normal distribution, where data is symmetrically distributed around the mean, there is no single mode. Instead, every data point has an equal frequency, and the distribution is considered unimodal.\n",
    "\n",
    "Graphically, a normal distribution looks like a symmetric \"bell-shaped\" curve, with the peak of the curve at the mean, and the mean, median, and mode all align at the center of the distribution.\n",
    "\n",
    "It's important to note that in real-world data, normal distributions are often approximations rather than perfect representations. In such cases, the measures of central tendency may not be exactly equal, but they will still be close to each other, indicating the general central location of the data.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-13\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Covariance and correlation are both measures used to quantify the relationship between two variables in statistics. However, they have some key differences in interpretation, scale, and usefulness:\n",
    "\n",
    "1. Definition:\n",
    "- Covariance: Covariance measures the joint variability of two variables. It indicates the degree to which the two variables change together. A positive covariance suggests that when one variable increases, the other tends to increase as well, and when one decreases, the other tends to decrease. A negative covariance suggests an inverse relationship, where one variable increases while the other decreases.\n",
    "- Correlation: Correlation is a standardized measure that quantifies the strength and direction of the linear relationship between two variables. It scales the covariance by the standard deviations of the two variables, resulting in a value between -1 and 1. A correlation of +1 indicates a perfect positive linear relationship, -1 indicates a perfect negative linear relationship, and 0 indicates no linear relationship.\n",
    "\n",
    "2. Scale:\n",
    "- Covariance: The magnitude of covariance depends on the scales of the variables being measured. As a result, it is difficult to compare covariances across different datasets or variables with different units. Consequently, covariance lacks a standardized scale.\n",
    "- Correlation: Correlation standardizes the covariance and scales it to a value between -1 and 1. This standardized scale makes it easy to interpret and compare correlations across different datasets and variables, regardless of their units.\n",
    "\n",
    "3. Interpretation:\n",
    "- Covariance: Covariance, on its own, does not provide a clear indication of the strength or direction of the relationship between two variables. Its positive or negative sign only indicates the direction, and the magnitude depends on the scales of the variables.\n",
    "- Correlation: Correlation provides a clear and interpretable measure of the strength and direction of the linear relationship between two variables. It allows easy comparison of relationships across different datasets, and its scale makes it more informative than covariance.\n",
    "\n",
    "4. Usefulness:\n",
    "- Covariance: Covariance is useful for understanding the joint variability of two variables. However, its limited interpretability and sensitivity to scales make it less widely used in practice compared to correlation.\n",
    "- Correlation: Correlation is extensively used in statistical analysis, as it provides a standardized measure of the strength and direction of the linear relationship between two variables. It is a fundamental tool in data analysis, particularly in fields like finance, economics, social sciences, and data science.\n",
    "\n",
    "In summary, covariance and correlation both measure the relationship between two variables, but correlation is more commonly used due to its standardized scale, ease of interpretation, and ability to compare relationships across different datasets.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ANS-14\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
